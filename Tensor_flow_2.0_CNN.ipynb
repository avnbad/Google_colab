{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensor_flow_2.0_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nq3yppz7myi0","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.python.ops import summary_ops_v2\n","from tensorflow import keras\n","from tensorflow.keras import datasets, layers, models, optimizers, metrics\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJ57XtUNnPfz","colab_type":"code","colab":{}},"source":["def mnist_datasets():\n","    (x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n","    # Numpy defaults to dtype=float64; TF defaults to float32. Stick with float32.\n","    x_train, x_test = x_train / np.float32(255), x_test / np.float32(255)\n","    y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n","    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","    return train_dataset, test_dataset\n","\n","\n","train_ds, test_ds = mnist_datasets()\n","train_ds = train_ds.shuffle(60000).batch(100)\n","test_ds = test_ds.batch(100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFaVeQSInPiw","colab_type":"code","colab":{}},"source":["model = tf.keras.Sequential([\n","    layers.Reshape(\n","        target_shape=[28, 28, 1],\n","        input_shape=(28, 28,)),\n","    layers.Conv2D(2, 5, padding='same', activation=tf.nn.relu),\n","    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n","    layers.Conv2D(4, 5, padding='same', activation=tf.nn.relu),\n","    layers.MaxPooling2D((2, 2), (2, 2), padding='same'),\n","    layers.Flatten(),\n","    layers.Dense(32, activation=tf.nn.relu),\n","    layers.Dropout(rate=0.4),\n","    layers.Dense(10)])\n","\n","optimizer = optimizers.SGD(learning_rate=0.01, momentum=0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U9FIunPhnPlx","colab_type":"code","colab":{}},"source":["compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kewYXJqknPvQ","colab_type":"code","colab":{}},"source":["def train_step(model, optimizer, images, labels):\n","\n","    # Record the operations used to compute the loss, so that the gradient\n","    # of the loss with respect to the variables can be computed.\n","    with tf.GradientTape() as tape:\n","        logits = model(images, training=True)\n","        loss = compute_loss(labels, logits)\n","        compute_accuracy(labels, logits)\n","\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gaqlabGCnPyJ","colab_type":"code","colab":{}},"source":["def train(model, optimizer, dataset, log_freq=50):\n","    \"\"\"\n","    Trains model on `dataset` using `optimizer`.\n","    \"\"\"\n","    # Metrics are stateful. They accumulate values and return a cumulative\n","    # result when you call .result(). Clear accumulated values with .reset_states()\n","    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n","\n","    # Datasets can be iterated over like any other Python iterable.\n","    for images, labels in dataset:\n","        loss = train_step(model, optimizer, images, labels)\n","        avg_loss(loss)\n","\n","        if tf.equal(optimizer.iterations % log_freq, 0):\n","            # summary_ops_v2.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n","            # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=optimizer.iterations)\n","            print('step:', int(optimizer.iterations),\n","                  'loss:', avg_loss.result().numpy(),\n","                  'acc:', compute_accuracy.result().numpy())\n","            avg_loss.reset_states()\n","            compute_accuracy.reset_states()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b74-cYevnP1R","colab_type":"code","colab":{}},"source":["def test(model, dataset, step_num):\n","    \"\"\"\n","    Perform an evaluation of `model` on the examples from `dataset`.\n","    \"\"\"\n","    avg_loss = metrics.Mean('loss', dtype=tf.float32)\n","\n","    for (images, labels) in dataset:\n","        logits = model(images, training=False)\n","        avg_loss(compute_loss(labels, logits))\n","        compute_accuracy(labels, logits)\n","\n","    print('Model test set loss: {:0.4f} accuracy: {:0.2f}%'.format(\n","        avg_loss.result(), compute_accuracy.result() * 100))\n","\n","    print('loss:', avg_loss.result(), 'acc:', compute_accuracy.result())\n","    # summary_ops_v2.scalar('loss', avg_loss.result(), step=step_num)\n","    # summary_ops_v2.scalar('accuracy', compute_accuracy.result(), step=step_num)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZqrHOJHlnP4J","colab_type":"code","colab":{}},"source":["# Where to save checkpoints, tensorboard summaries, etc.\n","MODEL_DIR = '/tmp/tensorflow/mnist'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVswSiDwoeuL","colab_type":"code","colab":{}},"source":["def apply_clean():\n","    if tf.io.gfile.exists(MODEL_DIR):\n","        print('Removing existing model dir: {}'.format(MODEL_DIR))\n","        tf.io.gfile.rmtree(MODEL_DIR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZzKeDtdoe5B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"99a28fff-62ff-43a7-db38-6a6b701828ee","executionInfo":{"status":"ok","timestamp":1557138619226,"user_tz":-330,"elapsed":1018,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["apply_clean()\n","\n","checkpoint_dir = os.path.join(MODEL_DIR, 'checkpoints')\n","checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n","\n","checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n","\n","# Restore variables on creation if a checkpoint exists.\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7fa7da6e1978>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"o-ctnxPeoe75","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"outputId":"53b60293-f335-444e-f735-3f2c5d4f19ef","executionInfo":{"status":"ok","timestamp":1557138669347,"user_tz":-330,"elapsed":46409,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["NUM_TRAIN_EPOCHS = 5\n","\n","for i in range(NUM_TRAIN_EPOCHS):\n","    start = time.time()\n","    #   with train_summary_writer.as_default():\n","    train(model, optimizer, train_ds, log_freq=500)\n","    end = time.time()\n","    print('Train time for epoch #{} ({} total steps): {}'.format(\n","        i + 1, int(optimizer.iterations), end - start))\n","    #   with test_summary_writer.as_default():\n","    #     test(model, test_ds, optimizer.iterations)\n","    checkpoint.save(checkpoint_prefix)\n","    print('saved checkpoint.')\n","\n","export_path = os.path.join(MODEL_DIR, 'export')\n","tf.saved_model.save(model, export_path)\n","print('saved SavedModel for exporting.')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["step: 500 loss: 1.5160028 acc: 0.47854\n","Train time for epoch #1 (600 total steps): 11.253653526306152\n","saved checkpoint.\n","step: 1000 loss: 0.6850984 acc: 0.76864\n","Train time for epoch #2 (1200 total steps): 8.305750846862793\n","saved checkpoint.\n","step: 1500 loss: 0.55123544 acc: 0.81578\n","Train time for epoch #3 (1800 total steps): 8.191735029220581\n","saved checkpoint.\n","step: 2000 loss: 0.472537 acc: 0.84022\n","Train time for epoch #4 (2400 total steps): 8.28259563446045\n","saved checkpoint.\n","step: 2500 loss: 0.42338306 acc: 0.85624\n","step: 3000 loss: 0.40138128 acc: 0.86994\n","Train time for epoch #5 (3000 total steps): 9.13263726234436\n","saved checkpoint.\n","saved SavedModel for exporting.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Vr-vurDoe-h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sAzGkCeLofA0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}