{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_RNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gTBIQ09d0_fO","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G52R7RJ21CdT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"313e305a-2d76-4e83-d010-df68fb562dc3","executionInfo":{"status":"ok","timestamp":1557728137650,"user_tz":-330,"elapsed":3888,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:01, 8504518.95it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 0/28881 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 130759.75it/s]           \n","  0%|          | 0/1648877 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 2154363.35it/s]                            \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 49128.08it/s]            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iqOEnIiU1CgK","colab_type":"code","colab":{}},"source":["batch_size = 100\n","n_iters = 3000\n","num_epochs = n_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVJ1hDtv1Cla","colab_type":"code","colab":{}},"source":["class RNNModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n","        super(RNNModel, self).__init__()\n","        # Hidden dimensions\n","        self.hidden_dim = hidden_dim\n","        \n","        # Number of hidden layers\n","        self.layer_dim = layer_dim\n","        \n","        # Building your RNN\n","        # batch_first=True causes input/output tensors to be of shape\n","        # (batch_dim, seq_dim, feature_dim)\n","        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n","        \n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","    \n","    def forward(self, x):\n","        # Initialize hidden state with zeros\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        if torch.cuda.is_available():\n","            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n","        else:\n","            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n","            \n","        # One time step\n","        out, hn = self.rnn(x, h0)\n","        \n","        # Index hidden state of last time step\n","        # out.size() --> 100, 28, 100\n","        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n","        out = self.fc(out[:, -1, :]) \n","        # out.size() --> 100, 10\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTzYYZql1CoK","colab_type":"code","colab":{}},"source":["input_dim = 28\n","hidden_dim = 100\n","layer_dim = 2  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n","output_dim = 10\n","\n","model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHDhbisW1Cqp","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dU5jrP3V1Cti","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OxiWewwK1Cv0","colab_type":"code","colab":{}},"source":["learning_rate = 0.1\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLytJTs_1C3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"de7ce652-6ee9-497d-8bf9-8fd26d54f1de","executionInfo":{"status":"ok","timestamp":1557728357782,"user_tz":-330,"elapsed":42313,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["# Number of steps to unroll\n","seq_dim = 28  \n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Load images as Variable\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        if torch.cuda.is_available():\n","            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n","            labels = Variable(labels.cuda())\n","        else:\n","            images = Variable(images.view(-1, seq_dim, input_dim))\n","            labels = Variable(labels)\n","            \n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","        \n","        # Forward pass to get output/logits\n","        # outputs.size() --> 100, 10\n","        outputs = model(images)\n","        \n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","        \n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","        \n","        # Updating parameters\n","        optimizer.step()\n","        \n","        iter += 1\n","        \n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n","                else:\n","                    images = Variable(images.view(-1, seq_dim, input_dim))\n","                \n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","                \n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # Total number of labels\n","                total += labels.size(0)\n","                \n","                # Total correct predictions\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum()\n","                else:\n","                    correct += (predicted == labels).sum()\n","            \n","            accuracy = 100 * correct / total\n","            \n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.27233627438545227. Accuracy: 90\n","Iteration: 1000. Loss: 0.2168554663658142. Accuracy: 93\n","Iteration: 1500. Loss: 0.22622115910053253. Accuracy: 94\n","Iteration: 2000. Loss: 0.24623948335647583. Accuracy: 94\n","Iteration: 2500. Loss: 0.261648952960968. Accuracy: 94\n","Iteration: 3000. Loss: 0.15902477502822876. Accuracy: 92\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6_ohnEYD1C6K","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}