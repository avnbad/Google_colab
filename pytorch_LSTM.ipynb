{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_LSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"JFUMszmADVVs","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-idfjNXuDdPT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"9459dc8c-32ec-4276-bed0-c8ba91e286a6","executionInfo":{"status":"ok","timestamp":1557815796462,"user_tz":-330,"elapsed":2241,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["  0%|          | 0/9912422 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:00, 23750243.68it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 350374.50it/s]\n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 6005455.57it/s]                           \n","8192it [00:00, 133580.09it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l2sg4PmgDdR0","colab_type":"code","colab":{}},"source":["batch_size = 100\n","n_iters = 3000\n","num_epochs = n_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7dtRpY0DdUS","colab_type":"code","colab":{}},"source":["class LSTMModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n","        super(LSTMModel, self).__init__()\n","        # Hidden dimensions\n","        self.hidden_dim = hidden_dim\n","        \n","        # Number of hidden layers\n","        self.layer_dim = layer_dim\n","        \n","        # Building your LSTM\n","        # batch_first=True causes input/output tensors to be of shape\n","        # (batch_dim, seq_dim, feature_dim)\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n","        \n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","    \n","    def forward(self, x):\n","        # Initialize hidden state with zeros\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","\n","        if torch.cuda.is_available():\n","            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n","        else:\n","            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n","        \n","        # Initialize cell state\n","        if torch.cuda.is_available():\n","            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n","        else:\n","            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n","        \n","        # One time step\n","        out, (hn, cn) = self.lstm(x, (h0,c0))\n","        \n","        # Index hidden state of last time step\n","        # out.size() --> 100, 28, 100\n","        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n","        out = self.fc(out[:, -1, :]) \n","        # out.size() --> 100, 10\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OR77kLUXDdWz","colab_type":"code","colab":{}},"source":["input_dim = 28\n","hidden_dim = 100\n","layer_dim = 3  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n","output_dim = 10\n","\n","model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRR6fR_wDdbG","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n84E_1W1Ddd0","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2LEt59aDdgM","colab_type":"code","colab":{}},"source":["learning_rate = 0.1\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L6rLHUo7DdiD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"cdc23078-9e1f-4859-baf8-c792eb06f55d","executionInfo":{"status":"ok","timestamp":1557816203989,"user_tz":-330,"elapsed":47002,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["# Number of steps to unroll\n","seq_dim = 28  \n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # Load images as Variable\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        if torch.cuda.is_available():\n","            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n","            labels = Variable(labels.cuda())\n","        else:\n","            images = Variable(images.view(-1, seq_dim, input_dim))\n","            labels = Variable(labels)\n","            \n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","        \n","        # Forward pass to get output/logits\n","        # outputs.size() --> 100, 10\n","        outputs = model(images)\n","        \n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","        \n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","        \n","        # Updating parameters\n","        optimizer.step()\n","        \n","        iter += 1\n","        \n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n","                else:\n","                    images = Variable(images.view(-1, seq_dim, input_dim))\n","                \n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","                \n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # Total number of labels\n","                total += labels.size(0)\n","                \n","                # Total correct predictions\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum()\n","                else:\n","                    correct += (predicted == labels).sum()\n","            \n","            accuracy = 100 * correct / total\n","            \n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 2.290208339691162. Accuracy: 11\n","Iteration: 1000. Loss: 2.281804084777832. Accuracy: 11\n","Iteration: 1500. Loss: 1.2780430316925049. Accuracy: 57\n","Iteration: 2000. Loss: 0.5942218899726868. Accuracy: 78\n","Iteration: 2500. Loss: 0.35958945751190186. Accuracy: 88\n","Iteration: 3000. Loss: 0.1865660846233368. Accuracy: 92\n"],"name":"stdout"}]}]}