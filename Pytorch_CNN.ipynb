{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9kWRe5fym_T_","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","from torch.autograd import Variable\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lktct_dwnI8P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"6e4adf42-b248-49e6-8b02-4daf50b22f55","executionInfo":{"status":"ok","timestamp":1557489872051,"user_tz":-330,"elapsed":8165,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:05, 1852296.79it/s]                             \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 432335.28it/s]\n","  1%|          | 16384/1648877 [00:00<00:11, 143609.27it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 7124807.81it/s]                           \n","8192it [00:00, 166942.34it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0rBZ5T5fnJmn","colab_type":"code","colab":{}},"source":["batch_size = 100\n","n_iters = 3000\n","num_epochs = n_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bo8SdRFhnJp3","colab_type":"code","colab":{}},"source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        \n","        # Convolution 1\n","        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n","        self.relu1 = nn.ReLU()\n","        \n","        # Max pool 1\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n","     \n","        # Convolution 2\n","        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","        \n","        # Max pool 2\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n","        \n","        # Fully connected 1 (readout)\n","        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n","    \n","    def forward(self, x):\n","        # Convolution 1\n","        out = self.cnn1(x)\n","        out = self.relu1(out)\n","        \n","        # Max pool 1\n","        out = self.maxpool1(out)\n","        \n","        # Convolution 2 \n","        out = self.cnn2(out)\n","        out = self.relu2(out)\n","        \n","        # Max pool 2 \n","        out = self.maxpool2(out)\n","        \n","        # Resize\n","        # Original size: (100, 32, 7, 7)\n","        # out.size(0): 100\n","        # New out size: (100, 32*7*7)\n","        out = out.view(out.size(0), -1)\n","\n","        # Linear function (readout)\n","        out = self.fc1(out)\n","        \n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3Z3LnCHn_ag","colab_type":"code","colab":{}},"source":["model = CNNModel()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXLhXX9ynJuf","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxTd_puCnJxG","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EJ65mfL7nJzH","colab_type":"code","colab":{}},"source":["learning_rate = 0.01\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGDBvVFjnJ1o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"3ddabcb9-7c00-4e0e-86e6-a339532cbc14","executionInfo":{"status":"ok","timestamp":1557489909951,"user_tz":-330,"elapsed":45964,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        \n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","        else:\n","            images = Variable(images)\n","            labels = Variable(labels)\n","        \n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","        \n","        # Forward pass to get output/logits\n","        outputs = model(images)\n","        \n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","        \n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","        \n","        # Updating parameters\n","        optimizer.step()\n","        \n","        iter += 1\n","        \n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    images = Variable(images.cuda())\n","                else:\n","                    images = Variable(images)\n","                \n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","                \n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # Total number of labels\n","                total += labels.size(0)\n","                \n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                # Total correct predictions\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum()\n","                else:\n","                    correct += (predicted == labels).sum()\n","            \n","            accuracy = 100 * correct / total\n","            \n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.2839554250240326. Accuracy: 89\n","Iteration: 1000. Loss: 0.2433609962463379. Accuracy: 91\n","Iteration: 1500. Loss: 0.19996650516986847. Accuracy: 94\n","Iteration: 2000. Loss: 0.16919171810150146. Accuracy: 95\n","Iteration: 2500. Loss: 0.13253498077392578. Accuracy: 96\n","Iteration: 3000. Loss: 0.1809445023536682. Accuracy: 96\n"],"name":"stdout"}]}]}