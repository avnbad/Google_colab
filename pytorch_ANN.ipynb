{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_ANN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vcJcUhbMmxnd","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_hNu2VrjnrCp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":275},"outputId":"b7a4ccf1-17c9-48db-eba2-5dfb467e8e50","executionInfo":{"status":"ok","timestamp":1557472943397,"user_tz":-330,"elapsed":7083,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:02, 3643138.13it/s]                             \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 57380.44it/s]                           \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:01, 959570.72it/s]                             \n","0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["8192it [00:00, 21409.60it/s]            "],"name":"stderr"},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PqUea3FynrFZ","colab_type":"code","colab":{}},"source":["batch_size = 100\n","n_iters = 3000\n","num_epochs = n_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CiUU8GTynrKw","colab_type":"code","colab":{}},"source":["class FeedforwardNeuralNetModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(FeedforwardNeuralNetModel, self).__init__()\n","        # Linear function 1: 784 --> 100\n","        self.fc1 = nn.Linear(input_dim, hidden_dim) \n","        # Non-linearity 1\n","        self.relu1 = nn.ReLU()\n","        \n","        # Linear function 2: 100 --> 100\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n","        # Non-linearity 2\n","        self.relu2 = nn.ReLU()\n","               \n","        # Linear function 4 (readout): 100 --> 10\n","        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n","    \n","    def forward(self, x):\n","        # Linear function 1\n","        out = self.fc1(x)\n","        # Non-linearity 1\n","        out = self.relu1(out)\n","        \n","        # Linear function 2\n","        out = self.fc2(out)\n","        # Non-linearity 2\n","        out = self.relu2(out)\n","               \n","        # Linear function 4 (readout)\n","        out = self.fc4(out)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQqGYgefnrVw","colab_type":"code","colab":{}},"source":["input_dim = 28*28\n","hidden_dim = 100\n","output_dim = 10\n","\n","model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vubOQ8qWnrZB","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHY4VNydnrbq","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sq4fGrSjnreR","colab_type":"code","colab":{}},"source":["learning_rate = 0.1\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YV1M2hXRnrg6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"abeac076-9fb0-4671-f599-4885f648999d","executionInfo":{"status":"ok","timestamp":1557473340554,"user_tz":-330,"elapsed":49478,"user":{"displayName":"avneet badhwar","photoUrl":"","userId":"15542508931799763923"}}},"source":["iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        \n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        if torch.cuda.is_available():\n","            images = Variable(images.view(-1, 28*28).cuda())\n","            labels = Variable(labels.cuda())\n","        else:\n","            images = Variable(images.view(-1, 28*28))\n","            labels = Variable(labels)\n","        \n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","        \n","        # Forward pass to get output/logits\n","        outputs = model(images)\n","        \n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","        \n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","        \n","        # Updating parameters\n","        optimizer.step()\n","        \n","        iter += 1\n","        \n","        if iter % 500 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for images, labels in test_loader:\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                images = Variable(images.view(-1, 28*28).cuda())\n","                \n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","                \n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # Total number of labels\n","                total += labels.size(0)\n","                \n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                # Total correct predictions\n","                correct += (predicted.cpu() == labels.cpu()).sum()\n","            \n","            accuracy = 100 * correct / total\n","            \n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data, accuracy))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.08318713307380676. Accuracy: 97\n","Iteration: 1000. Loss: 0.10619920492172241. Accuracy: 97\n","Iteration: 1500. Loss: 0.04786843806505203. Accuracy: 97\n","Iteration: 2000. Loss: 0.08684414625167847. Accuracy: 97\n","Iteration: 2500. Loss: 0.02733955904841423. Accuracy: 97\n","Iteration: 3000. Loss: 0.04973122477531433. Accuracy: 97\n"],"name":"stdout"}]}]}